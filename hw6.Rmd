---
title: "HW6 document"
output: github_document
---

```{r setup}
library(tidyverse)
library(modelr)
library(viridis)
library(mgcv)
set.seed(1)
```

### Problem 1

In the data cleaning code below we create a `city_state` variable, change `victim_age` to numeric, modifiy victim_race to have categories white and non-white, with white as the reference category, and create a `resolution` variable indicating whether the homicide is solved. Lastly, we filtered out the following cities: Tulsa, AL; Dallas, TX; Phoenix, AZ; and Kansas City, MO; and we retained only the variables `city_state`, `resolution`, `victim_age`, `victim_sex`, and `victim_race`.

```{r problem 1 cleaning}
homicide_df = 
  read_csv("homicide-data.csv", na = c("", "NA", "Unknown")) |> 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1)
  ) |> 
  filter(victim_race %in% c("White", "Black")) |> 
  filter(!(city_state %in% c("Tulsa, AL", "Dallas, TX", "Phoenix, AZ", "Kansas City, MO"))) |> 
  select(city_state, resolution, victim_age, victim_sex, victim_race)
```


```{r glm_baltimore}
baltimore_glm = 
  filter(homicide_df, city_state == "Baltimore, MD") |> 
  glm(resolution ~ victim_age + victim_sex + victim_race, family = binomial(), data = _)

baltimore_glm |> 
  broom::tidy() |> 
  mutate(
    OR = exp(estimate), 
    OR_CI_upper = exp(estimate + 1.96 * std.error),
    OR_CI_lower = exp(estimate - 1.96 * std.error)) |> 
  filter(term == "victim_sexMale") |> 
  select(OR, OR_CI_lower, OR_CI_upper) |>
  knitr::kable(digits = 3)
```

The odds ratio is 0.426, with confidence interval of 0.325 and 0.558. 


```{r q1_glm_all_cities}
model_results = 
  homicide_df |> 
  nest(data = -city_state) |> 
  mutate(
    models = map(data, \(df) glm(resolution ~ victim_age + victim_sex + victim_race, 
                             family = binomial(), data = df)),
    tidy_models = map(models, broom::tidy)) |> 
  select(-models, -data) |> 
  unnest(cols = tidy_models) |> 
  mutate(
    OR = exp(estimate), 
    OR_CI_upper = exp(estimate + 1.96 * std.error),
    OR_CI_lower = exp(estimate - 1.96 * std.error)) |> 
  filter(term == "victim_sexMale") |> 
  select(city_state, OR, OR_CI_lower, OR_CI_upper)

model_results |>
  slice(1:5) |> 
  knitr::kable(digits = 3)
```
Below we generate a plot of the estimated ORs and CIs for each city, ordered by magnitude of the OR from smallest to largest. From this plot we see that most cities have odds ratios that are smaller than 1, suggesting that crimes with male victims have smaller odds of resolution compared to crimes with female victims after adjusting for victim age and race. This disparity is strongest in New yrok. In roughly half of these cities, confidence intervals are narrow and do not contain 1, suggesting a significant difference in resolution rates by sex after adjustment for victim age and race. 

```{r q1_plot}
model_results |> 
  mutate(city_state = fct_reorder(city_state, OR)) |> 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = OR_CI_lower, ymax = OR_CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


### Problem 2

```{r download data problem2}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```


```{r Bootstrap analysis using weather data}
bootstrap_analysis = weather_df |>
  modelr::bootstrap(n = 5000) |>
  mutate(
    lm_models = map(strap, ~lm(tmax ~ tmin + prcp, data = .x)),
    glance_data = map(lm_models, broom::glance)
  ) |>
  select(glance_data) |>
  unnest(glance_data)

tidy_analysis = weather_df |>
  modelr::bootstrap(n = 5000) |>
  mutate(
    linear_models = map(strap, ~lm(tmax ~ tmin + prcp, data = .x)),
    tidy_data = map(linear_models, broom::tidy)
  ) |>
  select(tidy_data) |>
  unnest(tidy_data) |>
  select(term, estimate) |>
  pivot_wider(names_from = term, values_from = estimate) |>
  unnest()

# Bootstrap analysis with retaining 'term' and 'estimate'
tidy_analysis <- weather_df |>
  modelr::bootstrap(n = 5000) |>
  mutate(
    linear_models = map(strap, ~lm(tmax ~ tmin + prcp, data = .x)),
    tidy_data = map(linear_models, broom::tidy)
  ) |>
  select(strap, tidy_data) |>
  unnest(tidy_data)

tidy_analysis_adjusted <- tidy_analysis |>
  filter(term %in% c("tmin", "prcp")) |>
  group_by(strap) |>
  summarize(
    tmin_coeff = estimate[term == "tmin"],
    prcp_coeff = estimate[term == "prcp"]
  ) |>
  mutate(
    prod_coeff = tmin_coeff * prcp_coeff,
    logarithmic_value = log(prod_coeff)
  ) |>
  filter(!is.nan(logarithmic_value) & !is.infinite(logarithmic_value))

```


```{r adjusted calculation of logarithmic values}
tidy_analysis_adjusted <- tidy_analysis |>
  filter(term %in% c("tmin", "prcp")) |>
  group_by(strap) |>
  summarize(
    prod_coeff = prod(estimate[term == "tmin"] * estimate[term == "prcp"])
  ) |>
  mutate(
    logarithmic_value = log(prod_coeff)
  ) |>
  filter(!is.nan(logarithmic_value) & !is.infinite(logarithmic_value))

```

```{r Plotting the distribution of r-squared values}
r_squared_plot = bootstrap_analysis |>
  ggplot(aes(x = r.squared)) +
  geom_density()

print(r_squared_plot)

```


```{r Plotting the distribution of the logarithmic value}
log_value_plot_adjusted = tidy_analysis_adjusted |>
  ggplot(aes(x = logarithmic_value)) +
  geom_density()

print(log_value_plot_adjusted)
```

```{r Confidence intervals for R squared}
ci_r_squared_adjusted = bootstrap_analysis |> 
  summarize(
    lower_bound_r2 = quantile(r.squared, 0.025), 
    upper_bound_r2 = quantile(r.squared, 0.975)
  )

ci_r_squared_adjusted

```

```{r Calculating the confidence interval for the log value}
ci_log_value_adjusted = tidy_analysis_adjusted |>
  summarize(
    lower_bound_log = quantile(logarithmic_value, 0.025), 
    upper_bound_log = quantile(logarithmic_value, 0.975)
  )

ci_log_value_adjusted

```
The 95% confidence interval for r square is (0.889, 0.941).
he 95% confidence interval for log (beta1*beta2) is (-4.60, -9.26).


### Problem 3
```{r import data for probelm 3}
birthweight_df = read.csv('birthweight.csv', na =c("", "NA", "Unknown"))
```

```{r cleaning and names}
birthweight_df = birthweight_df |>
  mutate(
    babysex = recode(babysex, "1" = "male", "2" = "female"),
    frace = recode(frace, "1" = "White", "2" = "Black", "3" = "Asian", 
                        "4" = "Puerto Rico", "8" = "Others", "9" = "Unknown"),
    malform = recode(malform, "0" = "absent", "1" = "present"),
     mrace = recode(mrace,"1" = "White", "2" = "Black", "3" = "Asian", 
                        "4" = "Puerto Rico", "8" = "Others")
         )
```

## Propose a regression model for birthweight
My proposed regression model for birthweight `bwt` is a linear model that includes a wide range of predictors - both maternal characteristics and baby's characteristics. This model is a comprehensive approach, taking into account various factors that are hypothesized to impact birthweight.

Selection of Predictors: The predictors in your model encompass several categories:
Baby Characteristics: `babysex`, `blength`
Maternal Characteristics: `delwt` (delivery weight), `mheight` (mother's height), `momage` (mother's age), `parity` (number of live births), `ppbmi` (pre-pregnancy BMI), `ppwt` (pre-pregnancy weight), `wtgain` (weight gain during pregnancy)
Health and Lifestyle Factors: `malform` (presence of malformations), `smoken` (smoking habits)
Socioeconomic Factors: `fincome` (family income)
Race and Ethnicity: `frace` (father's race), `mrace` (mother's race)
Pregnancy Specifics: `gaweeks` (gestational age), `pnumlbw` (number of low birth weight babies previously), `pnumsga` (number of small for gestational age babies previously)
Hypothesis Behind Predictor Selection: The chosen predictors are based on existing research and theories regarding factors that influence birthweight. 

```{r model}

model <- lm(bwt ~ babysex + blength + delwt + fincome + frace + gaweeks + malform + menarche + mheight+ momage + mrace + parity + pnumlbw + pnumsga + ppbmi + ppwt + smoken + wtgain, 
            data = birthweight_df)

summary(model)
```
Several variables emerge as significant. Baby's length at birth (`blength`) and gestational age (`gaweeks`) are highly significant, indicating a strong positive association with birth weight. Notably, the baby's sex (`babysexmale`) also shows significance, suggesting a difference in birth weight between male and female babies. Mother's weight at delivery (`delwt`) and family income (`fincome`) positively correlate with birth weight, though the effect of income is relatively small. Interestingly, the mother's pre-pregnancy weight (`ppwt`) is negatively associated with birth weight, and maternal smoking (`smoken`) significantly reduces it, highlighting critical health considerations. Other factors, including race, presence of malformations, and mother's age at menarche, don't show significant impacts in this model. 

```{r plot}
birthweight_df <- birthweight_df |> 
  add_predictions(model, var = "preds") |> 
  add_residuals(model, var = "resids")

# Plot of residuals against fitted values
ggplot(birthweight_df, aes(x = preds, y = resids)) +
  geom_point() +
  geom_smooth(method = 'lm', se = FALSE) +
  labs(x = "Fitted Values", y = "Residuals", title = "Plot of Residuals vs Fitted Values")
```

## Compare models
```{r  length at birth and gestational age as predictors }
model_1 <- lm(bwt ~ blength + gaweeks, data = birthweight_df)

summary(model_1)
```

```{r Head Circumference, Length, Sex, and All Interactions}
model_2<- lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex, data = birthweight_df)

summary(model_2)
```

```{r cross-validation setup}
cv_df <- birthweight_df |> 
  modelr::crossv_mc(n = 100) |> 
  mutate(
    train_set = map(train, as_tibble),
    test_set = map(test, as_tibble)
  )
```


```{r Fit models on training sets and calculate RMSE on test sets}
cv_results <- cv_df |> 
  mutate(
    model_fit = map(train_set, ~lm(bwt ~ babysex + blength + delwt + fincome + frace + gaweeks + malform + menarche + mheight + momage + mrace + parity + pnumlbw + pnumsga + ppbmi + ppwt + smoken + wtgain, data = .x)),
    model_1_fit = map(train_set, ~lm(bwt ~ blength + gaweeks, data = .x)),
    model_2_fit = map(train_set, ~lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex, data = .x))
  ) |>
  mutate(
    rmse_model = map2_dbl(model_fit, test_set, ~modelr::rmse(.x, .y)),
    rmse_model_1 = map2_dbl(model_1_fit, test_set, ~modelr::rmse(.x, .y)),
    rmse_model_2 = map2_dbl(model_2_fit, test_set, ~modelr::rmse(.x, .y))
  )
```

```{r Summarizing the RMSE for each model}

summary_results <- cv_results |> 
  select(rmse_model, rmse_model_1, rmse_model_2) |> 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse"
  ) |> 
  group_by(model) |> 
  summarize(average_rmse = mean(rmse, na.rm = TRUE))

summary_results

```

Based on the comparison, model 1 which is length at birth and gestational age as predictors has the largest error of 337, following by my model and model 2. Which that model 2, Head Circumference, Length, Sex, and All Interactions, is the best model compare to my model and model_1 because it has the smallest error of 292. 

